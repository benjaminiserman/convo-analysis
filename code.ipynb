{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "from py_linq import Enumerable\n",
    "os.environ['R_HOME'] = 'C:\\Program Files\\R\\R-4.3.1'\n",
    "\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "base = importr('base')\n",
    "lsafun = importr('LSAfun')\n",
    "lsa = importr('lsa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': {'participant_id': 'Juliet', 'f_id': 'Juliet', 'm_id': 'Romeo', 'date.number': 1}, 'Text': \"What man art thou that, thus bescreened in night,\\nSo stumblest on my counsel?\\nMy ears have not yet drunk a hundred words\\nOf that tongue's uttering, yet I know the sound.\\nArt thou not Romeo and a Montague?\\nHow camest thou hither, tell me, and wherefore?\\nThe orchard walls are high and hard to climb,\\nAnd the place death, considering who thou art,\\nIf any of my kinsmen find thee here.\"}\n",
      "{'ID': {'participant_id': 'Romeo', 'f_id': 'Juliet', 'm_id': 'Romeo', 'date.number': 1}, 'Text': \"I take thee at thy word.\\nCall me but love, and I'll be new baptized;\\nHenceforth I never will be Romeo.\\nBy a name\\nI know not how to tell thee who I am.\\nMy name, dear saint, is hateful to myself,\\nBecause it is an enemy to thee.\\nHad I it written, I would tear the word.\\nNeither, fair maid, if either thee dislike.\"}\n"
     ]
    }
   ],
   "source": [
    "input_data = pandas.read_csv(\"Totally Real Conversation Data - Sheet1.csv\")\n",
    "aggregated_text_by_participant = Enumerable([row for _, row in input_data.iterrows()]) \\\n",
    "    .group_by(key_names=['participant_id', 'f_id', 'm_id', 'date.number'], key=lambda row: (row['ID'], row['F.ID'], row['M.ID'], row['Date.Number'])) \\\n",
    "    .select(lambda group: {'ID': group.key, 'Text': group \\\n",
    "        .select(lambda row: row['Event']) \\\n",
    "        .aggregate(lambda a, b: f\"{a}\\n{b}\")})\n",
    "    \n",
    "# LSA requires text *files* instead of just text for god knows why\n",
    "for entry in aggregated_text_by_participant:\n",
    "    print(entry)\n",
    "    participant_text_file = open(f\"participant_text_for_{entry['ID'].participant_id}.txt\", 'w')\n",
    "    participant_text_file.write(entry['Text'])\n",
    "    participant_text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: not all elements in x were found in rownames(tvectors)\n",
      "\n",
      "Note: not all elements in y were found in rownames(tvectors)\n",
      "\n",
      "[0.87993471]\n"
     ]
    }
   ],
   "source": [
    "tvectors = lsa.textmatrix(base.getwd())\n",
    "result = lsafun.costring(*aggregated_text_by_participant.select(lambda group: group['Text']), tvectors=tvectors)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
