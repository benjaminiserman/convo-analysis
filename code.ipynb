{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from py_linq import Enumerable\n",
    "os.environ[\"R_HOME\"] = \"C:\\Program Files\\R\\R-4.3.1\"\n",
    "\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = importr(\"base\")\n",
    "utils = importr(\"utils\")\n",
    "\n",
    "# install required dependencies\n",
    "dependencies = [\"lsa\", \"LSAfun\"]\n",
    "new_packages = [dependency for dependency in dependencies if dependency not in utils.installed_packages()]\n",
    "for new_package in new_packages:\n",
    "    print(f\"installing required dependency {new_package}\")\n",
    "    utils.install_packages(new_package, \"http://cran.us.r-project.org\")\n",
    "\n",
    "lsafun = importr(\"LSAfun\")\n",
    "lsa = importr(\"lsa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': {'participant_id': 'Juliet', 'f_id': 'Juliet', 'm_id': 'Romeo', 'date.number': 1}, 'Text': \"What man art thou that, thus bescreened in night,\\nSo stumblest on my counsel?\\nMy ears have not yet drunk a hundred words\\nOf that tongue's uttering, yet I know the sound.\\nArt thou not Romeo and a Montague?\\nHow camest thou hither, tell me, and wherefore?\\nThe orchard walls are high and hard to climb,\\nAnd the place death, considering who thou art,\\nIf any of my kinsmen find thee here.\"}\n",
      "{'ID': {'participant_id': 'Romeo', 'f_id': 'Juliet', 'm_id': 'Romeo', 'date.number': 1}, 'Text': \"I take thee at thy word.\\nCall me but love, and I'll be new baptized;\\nHenceforth I never will be Romeo.\\nBy a name\\nI know not how to tell thee who I am.\\nMy name, dear saint, is hateful to myself,\\nBecause it is an enemy to thee.\\nHad I it written, I would tear the word.\\nNeither, fair maid, if either thee dislike.\"}\n"
     ]
    }
   ],
   "source": [
    "file_names = glob.glob(\"convos/*.csv\")\n",
    "convo_data_frames = [pandas.read_csv(path) for path in file_names]\n",
    "input_data = pandas.concat(convo_data_frames, ignore_index=True)\n",
    "\n",
    "# aggregate text by participant and conversation. note that this currently treats conversations across different days separately\n",
    "aggregated_text_by_participant = Enumerable([row for _, row in input_data.iterrows()]) \\\n",
    "    .group_by(key_names=[\"participant_id\", \"f_id\", \"m_id\", \"date.number\"], \n",
    "              key=lambda row: (row[\"ID\"], row[\"F.ID\"], row[\"M.ID\"], row[\"Date.Number\"])) \\\n",
    "    .select(lambda group: {\"ID\": group.key, \"Text\": group \\\n",
    "        .select(lambda row: row[\"Event\"]) \\\n",
    "        .aggregate(lambda a, b: f\"{a}\\n{b}\")}) \\\n",
    "    .to_list()\n",
    "    \n",
    "# LSA requires text *files* instead of just text for god knows why\n",
    "for entry in aggregated_text_by_participant:\n",
    "    print(entry)\n",
    "    participant_text_file = open(f\"participant_text_for_{entry['ID'].participant_id}.txt\", \"w\")\n",
    "    participant_text_file.write(entry[\"Text\"])\n",
    "    participant_text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of pairs of participants who conversed\n",
    "convo_participant_pairs = Enumerable([row for _, row in input_data.iterrows()]) \\\n",
    "    .group_by(key_names=[\"f_id\", \"m_id\"], \n",
    "              key=lambda row: (row[\"F.ID\"], row[\"M.ID\"])) \\\n",
    "    .select(lambda group: { \"f_id\": group.key.f_id, \"m_id\": group.key.m_id })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_text=\"What man art thou that, thus bescreened in night, So stumblest on my counsel? My ears have not yet drunk a hundred words Of that tongue's uttering, yet I know the sound. Art thou not Romeo and a Montague? How camest thou hither, tell me, and wherefore? The orchard walls are high and hard to climb, And the place death, considering who thou art, If any of my kinsmen find thee here.\"\n",
      "m_text=\"I take thee at thy word. Call me but love, and I'll be new baptized; Henceforth I never will be Romeo. By a name I know not how to tell thee who I am. My name, dear saint, is hateful to myself, Because it is an enemy to thee. Had I it written, I would tear the word. Neither, fair maid, if either thee dislike.\"\n",
      "Note: not all elements in x were found in rownames(tvectors)\n",
      "\n",
      "Note: not all elements in y were found in rownames(tvectors)\n",
      "\n",
      "Result for Juliet & Romeo: [1] 0.5500876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tvectors = lsa.textmatrix(f\"{base.getwd()[0]}/convos\")\n",
    "base.load(\"TASA.rda\")\n",
    "\n",
    "for pair in convo_participant_pairs:\n",
    "    f_id = pair[\"f_id\"]\n",
    "    m_id = pair[\"m_id\"]\n",
    "    \n",
    "    # get first matching aggregated conversation for each participant\n",
    "    f_text = Enumerable(aggregated_text_by_participant).where(\n",
    "        lambda group: \n",
    "            group[\"ID\"].participant_id == f_id \n",
    "            and group[\"ID\"].f_id == f_id\n",
    "            and group[\"ID\"].m_id == m_id\n",
    "    ).select(lambda group: group[\"Text\"]).first()\n",
    "    \n",
    "    m_text = Enumerable(aggregated_text_by_participant).where(\n",
    "        lambda group: \n",
    "            group[\"ID\"].participant_id == m_id \n",
    "            and group[\"ID\"].f_id == f_id\n",
    "            and group[\"ID\"].m_id == m_id\n",
    "    ).select(lambda group: group[\"Text\"]).first()\n",
    "    \n",
    "    # replace any whitespace sequences with a single space\n",
    "    m_text = re.sub(r\"\\s+\", \" \", m_text)\n",
    "    f_text = re.sub(r\"\\s+\", \" \", f_text)\n",
    "    \n",
    "    # get cosine similarity between participants\" text\n",
    "    result = lsafun.costring(f_text, m_text, tvectors=rpy2.robjects.globalenv[\"TASA\"])\n",
    "    print(f\"Result for {f_id} & {m_id}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
